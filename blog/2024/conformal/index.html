<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> On conformal prediction (1/x) | John Cherian </title> <meta name="author" content="John Cherian"> <meta name="description" content="What is conformal prediction and why should we care about it?"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="jjcherian.github.io/blog/2024/conformal/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "On conformal prediction (1/x)",
            "description": "What is conformal prediction and why should we care about it?",
            "published": "February 18, 2024",
            "authors": [
              
              {
                "author": "John Cherian",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">John</span> Cherian </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>On conformal prediction (1/x)</h1> <p>What is conformal prediction and why should we care about it?</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#not-so-technical-background">(Not-so) Technical Background</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Recently, Ben Recht published a series of <a href="https://www.argmin.net/p/cover-songs" rel="external nofollow noopener" target="_blank">blog posts</a> about conformal prediction. I thought they made some interesting points, but really engaging with his critiques requires more than 140 characters and I’m definitely not going to start paying for X.</p> <div class="jekyll-twitter-plugin"> <blockquote class="twitter-tweet"> <p lang="en" dir="ltr">Explaining why I still think conformal is valuable despite these two observations deserves more than a Twitter thread. So maybe in the (not so near future), I'll write a blog post about this. But in the meantime, I think it's valuable to understand how a skeptic views the field.</p>— John Cherian (@jjcherian) <a href="https://twitter.com/jjcherian/status/1756027416655667313?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">February 9, 2024</a> </blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>So as it turns out, the (not so) near future is actually just about two weeks! But this is only part 1 (of 2 posts?)…so maybe my vague forecast will end up being correct after all.</p> <p>Anyways, you clicked on this link to learn about conformal prediction, so let’s get started by first motivating conformal prediction with a concrete problem. Imagine we’re trying to help a university admissions office admit students who are likely to succeed, so we fit a neural network trained on thousands of historical admissions records and college transcripts to predict a prospective student’s final GPA. The ever-astute admissions officer recognizes, however, that these point predictions are far from perfect. So, she asks “can you give me a <em>range</em> of GPAs that you can guarantee the student is likely to fall in?”</p> <p>At first glance, this sounds pretty hard! Predicting a range? Providing a guarantee? Those don’t sound like things that neural networks do. But don’t worry, if you hand it some data points that were held-out from neural network training, <strong>conformal prediction</strong> will solve exactly this task. Given the submitted applications (we’ll denote these by \(X_i\)) and final GPAs (we’ll call these \(Y_i\)) of \(n\) previous students, a conformal predictor makes use of the trained neural network to output a set for the \((n + 1)\)-st prospective student (referred to as \(\hat{C}_n(X_{n + 1})\)) that is guaranteed to contain the true GPA with some user-specified probability \(1 - \alpha\).</p> \[\Pr(Y_{n + 1} \in \hat{C}_n(X_{n + 1})) \geq 1 - \alpha\] <p>This guarantee is about as clean of a result as you’ll see in statistics. It requires only one assumption: the \((n + 1)\)-st student is drawn i.i.d. from the same distribution as the previous \(n\) students.<d-footnote>We can relax this assumption to exchangeability, but this won't really matter for our purposes.</d-footnote> Formally, we state this assumption as \(\{(X_i, Y_i)\}_{i = 1}^{n + 1} \stackrel{i.i.d.}{\sim} P\).</p> <p>So, why isn’t Ben satisfied? He argues that conformal prediction is sweeping two important details under the rug. The guarantee stated above is <em>marginal</em> over both the constructed prediction set function \(\hat{C}_n(\cdot)\) as well as the new students. In plain English, after reading Ben’s blog posts, the admissions officer might ask the following questions:</p> <ul> <li>Even if the prediction set covers the true GPA with high probability over a random new applicant, could it be terribly inaccurate for this particular student?</li> <li>What if, by chance, the \(n\) students you used to construct the prediction set were not representative of the data-generating distribution \(P\)? Even if I’m willing to settle for coverage that only holds marginally over a random new student, how big could the following deviation in the realized coverage possibly be?</li> </ul> \[D_n := \left |\Pr(Y_{n + 1} \in \hat{C}_n(X_{n + 1}) \mid \hat{C}_n(\cdot)) - (1 - \alpha) \right |\] <p>The first question relates to a research area sometimes referred to as ``conditional’’ predictive inference. It’ll be the topic of a subsequent blog post.<d-footnote>As a side note, is object-conditional predictive inference even what we want? It's certainly unclear for many ML problems. Imagine if I defined Y to be an image label and X to be the set of pixels input to a neural network. What's random about Y given X? Anyways, more on this later.</d-footnote></p> <p>The second question will be the subject of today’s post, but to come up with a satisfying answer, we’re going to have describe what conformal prediction actually does.</p> <h2 id="what-is-conformal-prediction-doing">What is conformal prediction doing?</h2> <p>While there are many methods that fall under the conformal prediction (CP) umbrella, the most popular by far is split CP. In split CP, we use the hold-out data set to construct a set of “conformity scores.” The choice for this conformity score that we will use as a running example is the absolute value of the observed residual,</p> \[S(X_i, Y_i) := |Y_i - f(X_i)|.\] <p>Then, the split conformal prediction set is defined as</p> \[\hat{C}_n(X_{n + 1}) = \left \{y : S(X_{n + 1}, y) \leq \text{Quantile}\left(\frac{\lceil (1 - \alpha) \cdot (n + 1) \rceil}{n}, \{S(X_i, Y_i)\}_{i = 1}^n \right) \right\}.\] <p>Parsing the definition of this prediction set to prove the validity claimed above isn’t too difficult, but it’s too easy to get lost in the details. To really understand what’s happening, let’s take a step back and think about what we might have done to construct a prediction set if no one had ever told us about split CP.</p> <p>Given a pretty good point predictor \(f(\cdot)\), the most natural construction for a prediction set is to simply add an error bar above and below the prediction, e.g.,</p> \[\hat{C}^{naive}_n(X_{n + 1}) = [f(X_{n + 1}) - \epsilon, f(X_{n + 1}) + \epsilon].\] <p>Intuitively, we need \(\epsilon\) to be larger than \((1 - \alpha)\)-% of the errors we expect to see on out-of-sample data. Lucky for us, we assumed access to a hold-out set that consists of exactly \(n\) such out-of-sample errors…so what if we just used the empirical \((1 - \alpha)\) quantile of those values? This method for choosing \(\epsilon\) yields a prediction set <em>nearly</em> identical to the split CP set. Hopefully, you can convince yourself that for this choice of \(\epsilon\), we can write</p> \[\hat{C}^{naive}_n(X_{n + 1}) = \left \{y : S(X_{n + 1}, y) \leq \text{Quantile}\left(1 - \alpha, \{S(X_i, Y_i)\}_{i = 1}^n \right) \right\}\] <p>So, is split CP really just a fancy way of saying use a hold-out set when you want to estimate prediction error?</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-02-18-conformal.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"jjcherian/jjcherian.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 John Cherian. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>