<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="introduction">Introduction</h2> <p>Recently, Ben Recht published a series of <a href="https://www.argmin.net/p/cover-songs" rel="external nofollow noopener" target="_blank">blog posts</a> about conformal prediction. I thought they made some interesting points, but really engaging with his critiques requires more than 140 characters and I’m definitely not going to start paying for X.</p> <div class="jekyll-twitter-plugin"> <blockquote class="twitter-tweet"> <p lang="en" dir="ltr">Explaining why I still think conformal is valuable despite these two observations deserves more than a Twitter thread. So maybe in the (not so near future), I'll write a blog post about this. But in the meantime, I think it's valuable to understand how a skeptic views the field.</p>— John Cherian (@jjcherian) <a href="https://twitter.com/jjcherian/status/1756027416655667313?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">February 9, 2024</a> </blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>So as it turns out, the (not so) near future is actually just about two weeks! But this is only part 1 (of 2 posts?)…so maybe my vague forecast will end up being correct after all.</p> <p>Anyways, you clicked on this link to learn about conformal prediction, so let’s get started by first motivating conformal prediction with a concrete problem. Imagine we’re trying to help a university admissions office admit students who are likely to succeed, so we fit a neural network trained on thousands of historical admissions records and college transcripts to predict a prospective student’s final GPA. The ever-astute admissions officer recognizes, however, that these point predictions are far from perfect. So, she asks “can you give me a <em>range</em> of GPAs that you can guarantee the student is likely to fall in?”</p> <p>At first glance, this sounds pretty hard! Predicting a range? Providing a guarantee? Those don’t sound like things that neural networks do. But don’t worry, if you hand it some data points that were held-out from neural network training, (split) <strong>conformal prediction</strong> will solve exactly this task. Given the submitted applications (we’ll denote these by \(X_i\)) and final GPAs (we’ll call these \(Y_i\)) of \(n\) previous students, a conformal predictor makes use of the trained neural network to output a set for the \((n + 1)\)-st prospective student (referred to as \(\hat{C}_n(X_{n + 1})\)) that is guaranteed to contain the true GPA with some user-specified probability \(1 - \alpha\).</p> \[\Pr(Y_{n + 1} \in \hat{C}_n(X_{n + 1})) \geq 1 - \alpha\] <p>This guarantee is about as clean of a result as you’ll see in statistics. It requires only one assumption: the \((n + 1)\)-st student is drawn i.i.d. from the same distribution as the previous \(n\) students.<d-footnote>We can relax this assumption to exchangeability, but this won't really matter for our purposes.</d-footnote></p> <p>So, why isn’t Ben satisfied? He argues that conformal prediction is sweeping two important details under the rug. The guarantee stated above is <em>marginal</em> over both the random data set used to construct \(\hat{C}_n(\cdot)\) as well as the applicant. In plain English, after reading Ben’s blog posts, the admissions officer might ask the following questions:</p> <ul> <li>Even if the prediction set covers the true GPA with high probability over a random new applicant, could it be terribly inaccurate for this particular student?</li> <li>Even if I’m willing to settle for coverage that only holds marginally over a random applicant, what if, by chance, the \(n\) students you used to construct the prediction set were not representative of the data-generating distribution \(P\)? In that case, how big could the following deviation in the realized coverage possibly be?</li> </ul> \[D_n := \left |\Pr(Y_{n + 1} \in \hat{C}_n(X_{n + 1}) \mid \hat{C}_n(\cdot)) - (1 - \alpha) \right |\] <p>The first question relates to a research area sometimes referred to as ``conditional’’ predictive inference. It’ll be the topic of a subsequent blog post.<d-footnote>As a side note, is object-conditional predictive inference even what we want? It's certainly unclear for many ML problems. Imagine if I defined Y to be an image label and X to be the set of pixels input to a neural network. What's random about Y given X? Anyways, more on this later.</d-footnote></p> <p>The second question will be the subject of today’s post, but to come up with a satisfying answer, we’re going to have describe what conformal prediction actually does.</p> <h2 id="what-is-conformal-prediction-doing">What is conformal prediction doing?</h2> <p>While there are many methods that fall under the conformal prediction (CP) umbrella, the most popular approach is split CP. In split CP, we use the hold-out data set to construct a set of “conformity scores.” The choice for this conformity score that we will use as a running example is the absolute value of the observed residual,</p> \[S(X_i, Y_i) := |Y_i - f(X_i)|.\] <p>While this choice of score is fairly naive, it makes it straightforward to interpret the resulting prediction set. This set \(\hat{C}_n(X_{n + 1})\) is the set of all $y$ such that \(S(X_{n + 1}, y)\) is less than some well-chosen threshold \(q^*\). Mathematically, conformal prediction transforms the prediction set membership problem into a simple quantile estimation problem:</p> \[\Pr(Y_{n + 1} \in \hat{C}_n(X_{n + 1})) = \Pr(S(X_{n + 1}, Y_{n + 1}) \leq q^*) \stackrel{?}{=} 1 - \alpha.\] <p>In split conformal prediction, we take \(q^*\) to be the \(\frac{\lceil (1 - \alpha) \cdot (n + 1) \rceil}{n}\) quantile of the \(n\) observed conformity scores. Putting all of this together, we define the split conformal prediction set as</p> \[\hat{C}_n(X_{n + 1}) = \left \{y : S(X_{n + 1}, y) \leq \text{Quantile}\left(\frac{\lceil (1 - \alpha) \cdot (n + 1) \rceil}{n}, \{S(X_i, Y_i)\}_{i = 1}^n \right) \right\}.\] <p>Parsing the definition of this prediction set to prove the coverage result above isn’t difficult, but it’s easy to lose the forest for the trees. To understand what’s happening, let’s take a step back and think about what we might have done to construct a prediction set if no one had ever told us about split CP.</p> <p>Given a pretty good point predictor \(f(\cdot)\), the most natural construction for a prediction set is to simply add and subtract a constant to the prediction, e.g.,</p> \[\hat{C}^{naive}_n(X_{n + 1}) = [f(X_{n + 1}) - \epsilon, f(X_{n + 1}) + \epsilon].\] <p>Intuitively, for this prediction set to be valid, we need \(\epsilon\) to be larger than \((1 - \alpha)\)-% of the errors we expect to see on out-of-sample data. Lucky for us, we already obtained a hold-out set that consists of exactly \(n\) such out-of-sample errors. So, here’s a naive strategy: what if we just used the empirical \((1 - \alpha)\) quantile of those values? This method for choosing \(\epsilon\) yields a prediction set <em>nearly</em> identical to the split CP \(\hat{C}_n(\cdot)\). Hopefully, you can convince yourself that for this choice of \(\epsilon\), we can write</p> \[\hat{C}^{naive}_n(X_{n + 1}) = \left \{y : S(X_{n + 1}, y) \leq \text{Quantile}\left(1 - \alpha, \{S(X_i, Y_i)\}_{i = 1}^n \right) \right\}\] <p>The difference between split CP and our naive strategy lies in this somewhat mysterious \(\frac{\lceil (1 - \alpha) \cdot (n + 1) \rceil}{n}\) value. To understand what that \(\frac{n + 1}{n}\) factor is doing for us, let’s first run an experiment to understand how it qualitatively affects our coverage.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;!--
  See https://www.debugbear.com/blog/responsive-images#w-descriptors-and-the-sizes-attribute and
  https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images for info on defining 'sizes' for responsive images
--&gt;

  &lt;source
    class="responsive-img-srcset"
    srcset="/assets/img/gaussian_empirical-480.webp 480w,/assets/img/gaussian_empirical-800.webp 800w,/assets/img/gaussian_empirical-1400.webp 1400w,"
    
      sizes="95vw"
    
    type="image/webp"
  &gt;

&lt;img
  src="/assets/img/gaussian_empirical.jpg"
  
    class="img-fluid rounded z-depth-1"
  
  
    width="100%"
  
  
    height="auto"
  
  
  
  
  
    data-zoomable
  
  
    loading="eager"
  
  onerror="this.onerror=null; $('.responsive-img-srcset').remove();"
&gt;
</code></pre></div></div> <p>&lt;/picture&gt;</p> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;/div&gt;
&lt;div class="col-sm mt-3 mt-md-0"&gt;
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/gaussian_conformal-480.webp 480w,/assets/img/gaussian_conformal-800.webp 800w,/assets/img/gaussian_conformal-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/gaussian_conformal.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;/div&gt;
</code></pre></div></div> <p>&lt;/div&gt; –&gt;</p> </body></html>